{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CM6VlGSMgcR"
   },
   "source": [
    "# Biomedical Image Classification via Dynamically Early Stopped Artificial Neural Network\n",
    "This code is for the Computerized Tomography MedMNIST datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3147,
     "status": "ok",
     "timestamp": 1665238996256,
     "user": {
      "displayName": "Ambra Catozzi",
      "userId": "00347062723157582254"
     },
     "user_tz": -120
    },
    "id": "LgaRHfSbMgcW"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "from models import ResNet18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aAXsW4PbMcpT"
   },
   "source": [
    "## Load MedMNIST: dataset informations and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665238996258,
     "user": {
      "displayName": "Ambra Catozzi",
      "userId": "00347062723157582254"
     },
     "user_tz": -120
    },
    "id": "xbXnT60cMcpZ"
   },
   "outputs": [],
   "source": [
    "data_flag =  'organsmnist' # or change dataset with 'octmnist' \n",
    "\n",
    "download = True\n",
    "\n",
    "NUM_EPOCHS = 50 # number of epochs\n",
    "BATCH_SIZE = 64 # mini-batch size\n",
    "lr = 0.01 # learning rate\n",
    "\n",
    "info = INFO[data_flag]\n",
    "task = info['task']\n",
    "n_channels = info['n_channels']\n",
    "n_classes = len(info['label'])\n",
    "\n",
    "DataClass = getattr(medmnist, info['python_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SR2ejRGwMcpZ"
   },
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[.5], std=[.5]) ])\n",
    "# Loading of the data and split up in to Training, Validation and Test set \n",
    "train_dataset = DataClass(split='train', transform=data_transform, download=download)\n",
    "val_dataset = DataClass(split='val', transform=data_transform, download=download)\n",
    "test_dataset = DataClass(split='test', transform=data_transform, download=download)\n",
    "# Data informations\n",
    "print(train_dataset)\n",
    "print(\"===================\")\n",
    "print(test_dataset)\n",
    "print(\"===================\")\n",
    "print(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UuHPl7U-Mcpa"
   },
   "outputs": [],
   "source": [
    "# Subdivision of the dataset\n",
    "# Concatenation of the original sets\n",
    "full_dataset = train_dataset + val_dataset + test_dataset\n",
    "\n",
    "# New split in Training, Validation and Test set\n",
    "# Training and provisory sets\n",
    "train_size = int(0.7 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_dataset, prov_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "# Test and Validation sets\n",
    "val_size = int(0.3 * len(prov_dataset))\n",
    "test_size = len(prov_dataset) - val_size\n",
    "val_dataset, test_dataset = torch.utils.data.random_split(prov_dataset, [val_size, test_size])\n",
    "\n",
    "pil_dataset = DataClass(split='train', download=download)\n",
    "\n",
    "# Encapsulate data into dataloader form\n",
    "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "\n",
    "val_loader = data.DataLoader(dataset=val_dataset, batch_size=2*BATCH_SIZE, shuffle=False) \n",
    "\n",
    "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hg2eOdSSMcpa"
   },
   "source": [
    "## Model, loss function and optimizer\n",
    "For other type of optimizer or loss function check on PyTorch documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnOEz3l9Mcpa"
   },
   "outputs": [],
   "source": [
    "# ResNet18 architecture\n",
    "model = ResNet18(in_channels=n_channels, num_classes=n_classes).cuda()\n",
    "    \n",
    "# Define loss function and optimizer\n",
    "if task == \"multi-label, binary-class\":\n",
    "    criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1WuPacRMcpa"
   },
   "source": [
    "## Functions for the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RW6RvWhUMcpa"
   },
   "outputs": [],
   "source": [
    "def eval_train_d():\n",
    "    # evaluation for training set\n",
    "    model.eval().cuda()\n",
    "    y_true = torch.tensor([]).cuda()\n",
    "    y_score = torch.tensor([]).cuda()\n",
    "    \n",
    "    data_loader = train_loader_at_eval\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            outputs = model(inputs).cuda()\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).cuda()\n",
    "                outputs = outputs.softmax(dim=-1).cuda()\n",
    "            else:\n",
    "                targets = targets.squeeze().long().cuda()\n",
    "                outputs = outputs.softmax(dim=-1).cuda()\n",
    "                targets = targets.float().resize_(len(targets), 1).cuda()\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0).cuda()\n",
    "            y_score = torch.cat((y_score, outputs), 0).cuda()\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.cpu().detach().numpy()\n",
    "        ind = np.argmax(y_score, axis = 1)\n",
    "\n",
    "        B = np.asarray(y_true).flatten()\n",
    "        acc = ( len(y_true) - len(np.nonzero(B - ind)[0] ) ) / len(y_true)\n",
    "    \n",
    "        print('Accuracy training: %.4f' % acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLWOqhKdMcpd"
   },
   "outputs": [],
   "source": [
    "def eval_val_d():\n",
    "    # evaluation for validation set\n",
    "    model.eval().cuda()\n",
    "    y_true = torch.tensor([]).cuda()\n",
    "    y_score = torch.tensor([]).cuda()\n",
    "    \n",
    "    data_loader = val_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            outputs = model(inputs).cuda()\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).cuda()\n",
    "                outputs = outputs.softmax(dim=-1).cuda()\n",
    "            else:\n",
    "                targets = targets.squeeze().long().cuda()\n",
    "                outputs = outputs.softmax(dim=-1).cuda()\n",
    "                targets = targets.float().resize_(len(targets), 1).cuda()\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0).cuda()\n",
    "            y_score = torch.cat((y_score, outputs), 0).cuda()\n",
    "\n",
    "        y_true = y_true.cpu().numpy() # true labels\n",
    "        y_score = y_score.cpu().detach().numpy() # probability\n",
    "        ind = np.argmax(y_score, axis = 1) # index of the max probability\n",
    "        B = np.asarray(y_true).flatten()\n",
    "\n",
    "        acc = ( len(y_true) - len(np.nonzero(B - ind)[0]) )  / len(y_true)\n",
    "    \n",
    "        print('Accuracy validation: %.4f' % acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJYUAH4jMcpe"
   },
   "outputs": [],
   "source": [
    "def eval_test_d():\n",
    "    # evaluation for test set\n",
    "    model.eval().cuda()\n",
    "    y_true = torch.tensor([]).cuda()\n",
    "    y_score = torch.tensor([]).cuda()\n",
    "    \n",
    "    data_loader = test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs = inputs.cuda()\n",
    "            targets = targets.cuda()\n",
    "            outputs = model(inputs).cuda()\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32).cuda()\n",
    "                outputs = outputs.softmax(dim=-1).cuda()\n",
    "            else:\n",
    "                targets = targets.squeeze().long().cuda()\n",
    "                outputs = outputs.softmax(dim=-1).cuda()\n",
    "                targets = targets.float().resize_(len(targets), 1).cuda()\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0).cuda()\n",
    "            y_score = torch.cat((y_score, outputs), 0).cuda()\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.cpu().detach().numpy()\n",
    "        ind = np.argmax(y_score, axis = 1)\n",
    "\n",
    "        B = np.asarray(y_true).flatten()\n",
    "        acc = ( len(y_true) - len(np.nonzero(B - ind)[0]) ) / len(y_true)\n",
    "    \n",
    "        print('Accuracy test: %.4f' % acc)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KF6VmpxbMcpe"
   },
   "source": [
    "## Original ResNet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eTyvDNYbMgce",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(epoch)\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs).cuda()\n",
    "        \n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).cuda()\n",
    "            loss = criterion(outputs, targets).cuda()\n",
    "        else:\n",
    "            targets = targets.squeeze().long().cuda()\n",
    "            loss = criterion(outputs, targets).cuda()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aae6qo0vMgcf"
   },
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "print('Evaluating ...')\n",
    "eval_train_d()\n",
    "eval_val_d()\n",
    "acc = eval_test_d()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQsG9AtJMgcf"
   },
   "source": [
    "## ResNet 18 with classical Early Stopping (ES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiPHAvsEMgcf"
   },
   "outputs": [],
   "source": [
    "acc_val_best = 0 # the initial accuracy on validation set is set to zero\n",
    "patience = 20 # patience value\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1p4x-BUFMgcf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('Epoch number: %d'% epoch)\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    model.train().cuda()\n",
    "    for inputs, targets in tqdm(train_loader):\n",
    "        # forward, backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        outputs = model(inputs).cuda()\n",
    "\n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).cuda()\n",
    "            loss = criterion(outputs, targets).cuda()\n",
    "        else:\n",
    "            targets = targets.squeeze().long().cuda()\n",
    "            loss = criterion(outputs, targets).cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    acc_train = eval_train_d()\n",
    "    acc_val = eval_val_d()\n",
    "    acc_test = eval_test_d()\n",
    "    \n",
    "    if acc_val > acc_val_best:\n",
    "        counter = 0\n",
    "        acc_val_best = acc_val\n",
    "        acc_test_save = acc_test\n",
    "        last_epoch = epoch\n",
    "        model_best = model.train().cuda() \n",
    "        print('Counter: %d \\n\\n'% counter)\n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        print('Counter: %d \\n\\n'% counter)\n",
    "\n",
    "    if counter>patience:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0MYoNGijMcpf"
   },
   "source": [
    "## ResNet18 with LRBS, i.e. learning rate decreasing (LR) and mini-batch size increasing (BS)\n",
    "In the following cell, it's possible to set the initial hyperparameters and the optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bMavsXe1kqbc"
   },
   "outputs": [],
   "source": [
    "acc_val_best = 0\n",
    "patience = 20\n",
    "counter = 0\n",
    "counter2 = 0\n",
    "lr = 0.01 # learining rate\n",
    "bs = BATCH_SIZE\n",
    "batch_inc = 64 # mini-batch size for increasing\n",
    "bs = 64 # initial mini-batch size\n",
    "c2 = 0 \n",
    "NUM_EPOCHS = 50 \n",
    "spatience = 10\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HochIbMVk1l_"
   },
   "outputs": [],
   "source": [
    "for epoch in range(NUM_EPOCHS):\n",
    "    print('Epoch number: %d \\t'% epoch)\n",
    "    print('LR: %f '% lr)\n",
    "    print('Batch size: %d '% bs)\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "    model.train().cuda()\n",
    "    for inputs, targets in tqdm(data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)):\n",
    "        # forward + backward + optimize\n",
    "        optimizer.zero_grad()\n",
    "        inputs = inputs.cuda()\n",
    "        targets = targets.cuda()\n",
    "        outputs = model(inputs).cuda()\n",
    "\n",
    "        if task == 'multi-label, binary-class':\n",
    "            targets = targets.to(torch.float32).cuda()\n",
    "            loss = criterion(outputs, targets).cuda()\n",
    "        else:\n",
    "            targets = targets.squeeze().long().cuda()\n",
    "            loss = criterion(outputs, targets).cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    acc_train = eval_train_d()\n",
    "    acc_val = eval_val_d()\n",
    "    acc_test = eval_test_d()\n",
    "    \n",
    "    if acc_val > acc_val_best:\n",
    "        counter = 0\n",
    "        counter2 = 0\n",
    "        acc_val_best = acc_val\n",
    "        acc_test_best = acc_test\n",
    "        last_epoch_LRBS = epoch\n",
    "        model_best = model.train().cuda() \n",
    "        print('Counter: %d \\n\\n'% counter)        \n",
    "    else:\n",
    "        counter = counter + 1\n",
    "        counter2 = counter2 + 1\n",
    "        print('Counter: %d \\n\\n'% counter)\n",
    "        if counter2 == spatience:\n",
    "            spatience = np.ceil(spatience/2)\n",
    "            counter2=0\n",
    "            c2 = c2 + 1\n",
    "            if c2%2 == 1:\n",
    "                lr = lr*0.5\n",
    "                optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "            else:\n",
    "                bs = bs + batch_inc\n",
    "\n",
    "    if counter>patience:\n",
    "        break\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
